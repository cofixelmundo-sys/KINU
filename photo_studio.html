<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>KINU Studio AI - TensorFlow Edition</title>
    <script src="https://cdn.tailwindcss.com"></script>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.2.0"></script>
</head>
<body class="bg-zinc-950 text-white min-h-screen flex flex-col items-center justify-center p-6 font-sans">

    <div class="mb-8 text-center">
        <h1 class="text-indigo-500 font-black tracking-widest text-xl uppercase italic">KINU STUDIO</h1>
        <p class="text-zinc-500 text-[10px] mt-2 uppercase tracking-widest font-bold">TensorFlow.js Engine</p>
    </div>

    <div class="relative w-full max-w-[320px] aspect-[3/4] bg-zinc-900 rounded-[40px] overflow-hidden border border-white/10 shadow-2xl">
        
        <div id="drop-zone" class="absolute inset-0 z-30 flex flex-col items-center justify-center bg-zinc-900 px-8">
            <label class="w-full bg-indigo-600 text-white text-[11px] font-black py-4 px-8 rounded-2xl cursor-pointer shadow-lg uppercase tracking-widest text-center active:scale-95 transition-all">
                TOMAR FOTO
                <input type="file" id="file-input" class="hidden" accept="image/*">
            </label>
        </div>

        <div id="loading-overlay" class="hidden absolute inset-0 z-40 flex flex-col items-center justify-center bg-zinc-950/95 backdrop-blur-md px-10 text-center">
            <div class="w-10 h-10 border-2 border-indigo-500 border-t-transparent rounded-full animate-spin mb-4"></div>
            <p id="loader-msg" class="text-[10px] font-black tracking-widest text-indigo-400 uppercase">Iniciando Tensor...</p>
        </div>

        <canvas id="process-canvas" class="hidden"></canvas>
        
        <img id="result-img" class="relative z-10 w-full h-full object-contain p-4 opacity-0 transition-opacity duration-500">
    </div>

    <button id="final-btn" onclick="confirmar()" disabled class="mt-8 w-full max-w-[320px] py-4 bg-zinc-800 text-zinc-600 rounded-2xl font-black text-[10px] uppercase tracking-[0.3em] transition-all">
        Confirmar Resultado
    </button>

    <script>
        const fileInput = document.getElementById('file-input');
        const loaderMsg = document.getElementById('loader-msg');
        let net;

        // Cargar el modelo de TensorFlow al iniciar
        async function loadModel() {
            loaderMsg.innerText = "Cargando IA...";
            net = await bodyPix.load({
                architecture: 'MobileNetV1',
                outputStride: 16,
                multiplier: 0.75,
                quantBytes: 2
            });
            console.log("BodyPix Cargado");
        }

        fileInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;

            document.getElementById('loading-overlay').classList.remove('hidden');
            document.getElementById('drop-zone').classList.add('hidden');

            if (!net) await loadModel();
            
            loaderMsg.innerText = "Analizando silueta...";
            
            const img = new Image();
            img.src = URL.createObjectURL(file);
            img.onload = async () => {
                // Procesar la segmentación
                const segmentation = await net.segmentPerson(img, {
                    flipHorizontal: false,
                    internalResolution: 'medium',
                    segmentationThreshold: 0.7
                });

                const canvas = document.getElementById('process-canvas');
                const ctx = canvas.getContext('2d');
                canvas.width = img.width;
                canvas.height = img.height;

                // Dibujar imagen original
                ctx.drawImage(img, 0, 0);
                
                // Obtener datos de pixeles
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                const pixelData = imageData.data;

                // Volver transparente lo que no sea la persona
                for (let i = 0; i < segmentation.data.length; i++) {
                    if (segmentation.data[i] === 0) { // 0 significa "fondo"
                        pixelData[i * 4 + 3] = 0; // Opacidad 0
                    }
                }

                ctx.putImageData(imageData, 0, 0);

                // Mostrar resultado
                const finalImg = document.getElementById('result-img');
                finalImg.src = canvas.toDataURL("image/png");
                finalImg.onload = () => {
                    finalImg.classList.remove('opacity-0');
                    document.getElementById('loading-overlay').classList.add('hidden');
                    const btn = document.getElementById('final-btn');
                    btn.disabled = false;
                    btn.innerText = "GUARDAR RETRATO";
                    btn.className = "mt-8 w-full max-w-[320px] py-4 bg-indigo-600 text-white rounded-2xl font-black text-[10px] uppercase tracking-[0.3em] shadow-xl";
                    
                    sessionStorage.setItem('imagen_procesada', finalImg.src);
                };
            };
        });

        function confirmar() {
            if (window.parent) window.parent.postMessage("completado", "*");
            alert("¡Foto procesada con TensorFlow!");
        }

        // Pre-cargar modelo
        loadModel().catch(console.error);
    </script>
</body>
</html>
